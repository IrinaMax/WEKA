Prediscretization vs Pre-built distcetizations
How good is J48’s built-in discretization compared with Weka’s supervised Discretize filter with the makeBinary option set (probably the 
best configuration of all the discretization filters)?

Use the Experimenter to compare the two on these datasets: diabetes.arff, glass.arff, ionosphere.arff, iris.arff, and schizo.arff 
( default settings throughout).


Weka Result:

Tester:     weka.experiment.PairedCorrectedTTester -G 4,5,6 -D 1 -R 2 -S 0.05 -V -result-matrix "weka.experiment.ResultMatrixPlainText -mean-prec 2 -stddev-prec 2 -col-name-width 0 -row-name-width 25 -mean-width 2 -stddev-width 2 -sig-width 1 -count-width 5 -show-stddev -print-col-names -print-row-names -enum-col-names"
Analysing:  Percent_correct
Datasets:   5
Resultsets: 2
Confidence: 0.05 (two tailed)
Sorted by:  -
Date:       3/29/18 10:52 PM


Dataset                   (1) meta.FilteredCl | (2) trees.J48 '
---------------------------------------------------------------
pima_diabetes            (100)   74.32( 4.78) |   74.49(5.27)  
Glass                    (100)   72.31(10.15) |   67.63(9.31)  
ionosphere               (100)   90.12( 4.87) |   89.74(4.38)  
iris                     (100)   93.60( 5.27) |   94.73(5.30)  
schizo-                  (100)   72.35(11.46) |   82.32(8.80) v
---------------------------------------------------------------
                                      (v/ /*) |         (1/4/0)


Key:
(1) meta.FilteredClassifier '-F \"supervised.attribute.Discretize -R first-last -precision 6\" -S 1 -W trees.J48 -- -C 0.25 -M 2' -4523450618538717400
(2) trees.J48 '-C 0.25 -M 2' -217733168393644444




Question 1
For which datasets does J48’s built-in discretization give better results than the FilteredClassifer?
We can see Diabeties, Iris and Schizo  trees J48 give better result then Meta.

Question2.
Schizo dataset does J48’s built-in discretization give significantly better results (at the 5% level).

Question3
Repeat with the classifiers JRip and PART (use default settings throughout), comparing them on the above datasets with and 
without Weka’s supervised Discretize filter with the makeBinary option set. This time, look at just the results that are statistically 
significant (at the 5% level).

For which dataset (if any) does JRip’s built-in discretization gives significantly better results than the Filtered Classifer?
Answer: Schizo, look at the Weka tester result.

Tester:     weka.experiment.PairedCorrectedTTester -G 4,5,6 -D 1 -R 2 -S 0.05 -V -result-matrix "weka.experiment.ResultMatrixPlainText -mean-prec 2 -stddev-prec 2 -col-name-width 0 -row-name-width 25 -mean-width 2 -stddev-width 2 -sig-width 1 -count-width 5 -show-stddev -print-col-names -print-row-names -enum-col-names"
Analysing:  Percent_correct
Datasets:   5
Resultsets: 4
Confidence: 0.05 (two tailed)
Sorted by:  -
Date:       3/29/18 11:01 PM


Dataset                   (1) rules.JRip '-F | (2) meta.Filtere (3) rules.PART ' (4) meta.Filtere
-------------------------------------------------------------------------------------------------
pima_diabetes            (100)   75.18(4.54) |   74.35( 4.85)     73.45( 4.51)     74.12( 4.84)  
Glass                    (100)   66.78(9.65) |   68.35( 9.27)     68.75(10.60)     71.85( 9.85)  
ionosphere               (100)   89.16(4.64) |   90.92( 5.18)     90.83( 4.66)     89.41( 4.72)  
iris                     (100)   94.47(5.85) |   93.33( 5.53)     94.20( 5.25)     94.20( 5.50)  
schizo-                  (100)   82.85(7.28) |   70.29(11.63) *   76.59( 9.93)     72.26(11.50) *
-------------------------------------------------------------------------------------------------
                                     (v/ /*) |          (0/4/1)          (0/5/0)          (0/4/1)

Key:
(1) rules.JRip '-F 3 -N 2.0 -O 2 -S 1' -6589312996832147161
(2) meta.FilteredClassifier '-F \"supervised.attribute.Discretize -R first-last -precision 6\" -S 1 -W rules.JRip -- -F 3 -N 2.0 -O 2 -S 1' -4523450618538717400
(3) rules.PART '-M 2 -C 0.25 -Q 1' 8121455039782598361
(4) meta.FilteredClassifier '-F \"supervised.attribute.Discretize -R first-last -precision 6\" -S 1 -W rules.PART -- -M 2 -C 0.25 -Q 1' -4523450618538717400

SMO and Log--------
Tester:     weka.experiment.PairedCorrectedTTester -G 4,5,6 -D 1 -R 2 -S 0.05 -V -result-matrix "weka.experiment.ResultMatrixPlainText -mean-prec 2 -stddev-prec 2 -col-name-width 0 -row-name-width 25 -mean-width 2 -stddev-width 2 -sig-width 1 -count-width 5 -show-stddev -print-col-names -print-row-names -enum-col-names"
Analysing:  Percent_correct
Datasets:   5
Resultsets: 4
Confidence: 0.05 (two tailed)
Sorted by:  -
Date:       3/29/18 11:26 PM


Dataset                   (1) functions.SMO  | (2) meta.Filtere (3) functions.L (4) meta.Filtere
------------------------------------------------------------------------------------------------
pima_diabetes            (100)   76.80(4.54) |   74.48( 4.61)     77.47(4.39)     75.57( 4.34)  
Glass                    (100)   57.36(8.77) |   72.04( 9.52) v   62.89(9.22)     69.69( 9.36) v
ionosphere               (100)   88.07(5.32) |   90.18( 4.83)     87.72(5.57)     84.62( 5.21)  
iris                     (100)   96.27(4.58) |   94.13( 5.38)     97.20(4.46)     93.47( 5.68)  
schizo-                  (100)   58.76(7.32) |   69.82(10.38) v   60.91(7.54)     71.71(11.68) v
------------------------------------------------------------------------------------------------
                                     (v/ /*) |          (2/3/0)         (0/5/0)          (2/3/0)


Key:
(1) functions.SMO '-C 1.0 -L 0.001 -P 1.0E-12 -N 0 -V -1 -W 1 -K \"functions.supportVector.PolyKernel -E 1.0 -C 250007\" -calibrator \"functions.Logistic -R 1.0E-8 -M -1 -num-decimal-places 4\"' -6585883636378691736
(2) meta.FilteredClassifier '-F \"supervised.attribute.Discretize -R first-last -precision 6\" -S 1 -W functions.SMO -- -C 1.0 -L 0.001 -P 1.0E-12 -N 0 -V -1 -W 1 -K \"functions.supportVector.PolyKernel -E 1.0 -C 250007\" -calibrator \"functions.Logistic -R 1.0E-8 -M -1 -num-decimal-places 4\"' -4523450618538717400
(3) functions.Logistic '-R 1.0E-8 -M -1 -num-decimal-places 4' 3932117032546553727
(4) meta.FilteredClassifier '-F \"supervised.attribute.Discretize -R first-last -precision 6\" -S 1 -W functions.Logistic -- -R 1.0E-8 -M -1 -num-decimal-places 4' -4523450618538717400

Q13
IBk can implement arbitrary boundaries in instance space.
How would you expect pre-discretization to affect IBk’s performance?
Answer: Pre-discretization would not change its performance significantly.

Testing IBk on the same 5 datasets: pre-discretization significantly NOT improve IBk’s performance.

Tester:     weka.experiment.PairedCorrectedTTester -G 4,5,6 -D 1 -R 2 -S 0.05 -V -result-matrix "weka.experiment.ResultMatrixPlainText -mean-prec 2 -stddev-prec 2 -col-name-width 0 -row-name-width 25 -mean-width 2 -stddev-width 2 -sig-width 1 -count-width 5 -show-stddev -print-col-names -print-row-names -enum-col-names"
Analysing:  Percent_correct
Datasets:   5
Resultsets: 2
Confidence: 0.05 (two tailed)
Sorted by:  -
Date:       3/30/18 11:41 PM


Dataset                   (1) meta.FilteredCl | (2) lazy.IBk '-
---------------------------------------------------------------
pima_diabetes            (100)   73.60( 4.59) |   70.62(4.67)  
Glass                    (100)   75.17(10.27) |   69.95(8.43)  
ionosphere               (100)   91.71( 4.42) |   87.10(5.12) *
iris                     (100)   93.47( 5.76) |   95.40(4.80)  
schizo-                  (100)   68.03(10.53) |   60.09(7.72)  
---------------------------------------------------------------
                                      (v/ /*) |         (0/4/1)


Key:
(1) meta.FilteredClassifier '-F \"supervised.attribute.Discretize -R first-last -precision 6\" -S 1 -W lazy.IBk -- -K 1 -W 0 -A \"weka.core.neighboursearch.LinearNNSearch -A \\\"weka.core.EuclideanDistance -R first-last\\\"\"' -4523450618538717400
(2) lazy.IBk '-K 1 -W 0 -A \"weka.core.neighboursearch.LinearNNSearch -A \\\"weka.core.EuclideanDistance -R first-last\\\"\"' -3080186098777067172




